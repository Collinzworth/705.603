{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9 Part A: Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and preprocessing plan\n",
    "A high sparsity exists, with ~0.5% of all transactions being fraud transactions.\n",
    "\n",
    "#### Time\n",
    "Going to need to convert date to seperate year-month-weekday columns. Will drop \"unix_time\" column since it contains highly duplicate data as the transaction date and time column. Granularity of time of day could be explored, but for now a simple day-month-year will be the first plan of attack.\n",
    "\n",
    "#### Customer Information\n",
    "\n",
    "Customer first and last name can be dropped in favor of the cc_num column. Customer's date of birth will be converted to simply how many years old they are. Their employment will be kept due to this providing valuable information of potential fraud transactions. The sex field is potentially ommitable, so if increased model performance is required removing sex will be among the first strategies. CC_num is a database index and does not provide true value to the analysis, therefore it will be dropped as well.\n",
    "\n",
    "**EDIT**\n",
    "After some experimentation, I found customer CC number to not be ordinal and creating categorically encoding it is unfeasible. I believe the name to be valuable and which customer it is coming from, but worried it will introduce too much sparsity when encoded. Future models could incorporate these data points by introducing some form of dimensionality reduction.\n",
    "\n",
    "#### Merchant information\n",
    "Merchant and category of purchase will need to be one-hot encoded. The amount of the transaction is valuable and will be scaled via normalization. Transaction number can be dropped as well since it is not providing any additional value.\n",
    "\n",
    "\n",
    "#### Geographic Information\n",
    "\n",
    "Lat-Lon combinations of both merchant and customer will not be used since not much valuable insight was obtained during data exploration. Customer street will also be dropped in favor of the city and city information as geographic information for the customer since I suspect it is too high detail and will be represented to some degree by the city column. Zip will also be dropped in favor of city and state.\n",
    "\n",
    "\n",
    "City population will be kept also. This could potentially have duplicate information stored in it since city itself is also a field. These two fields might be worth looking into further for processing.\n",
    "\n",
    "\n",
    "## Encoding Scheme\n",
    "\n",
    "Year and month will naturally be ordinally encoded. Week day however should be one-hot encoded since it is categorical over ordinal. Employment, merchant, and category will be one-hot encoded. The remainder of the numerical fields will be scaled using standardization.\n",
    "\n",
    "**EDIT**\n",
    " After experimenting, I found out that one-hot encoding every categorical field eats too much RAM. I decided on one-hot encoding state and employment. This was because state will capture geographical information while employment captures information about the person. City and category were dropped due to hardware limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_dataset = pd.read_csv(\"transactions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unwanted Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate year-month-weekday and delete \"trans_date_trans_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "year_column = [datetime.strptime(row_date, date_format).year for row_date in fraud_dataset.trans_date_trans_time]\n",
    "month_column = [datetime.strptime(row_date, date_format).month for row_date in fraud_dataset.trans_date_trans_time]\n",
    "weekday_column = [(datetime.strptime(row_date, date_format).toordinal()%7 + 1) for row_date in fraud_dataset.trans_date_trans_time]\n",
    "\n",
    "input_data = {\"year\": year_column,\n",
    "              \"month\": month_column,\n",
    "              \"weekday\": weekday_column}\n",
    "\n",
    "time_encoded_df = pd.DataFrame(data=input_data)\n",
    "\n",
    "del year_column\n",
    "del month_column\n",
    "del weekday_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Weekday Data\n",
    "weekday_encoder = OneHotEncoder()\n",
    "weekday_encoder.fit(time_encoded_df[\"weekday\"].to_numpy().reshape(-1, 1))\n",
    "weekday_encoded_values = weekday_encoder.fit_transform(time_encoded_df[['weekday']]).toarray()\n",
    "\n",
    "weekday_encoded_df = pd.DataFrame(weekday_encoded_values, columns=weekday_encoder.get_feature_names_out())\n",
    "weekday_encoded_df.head()\n",
    "\n",
    "del weekday_encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weekday_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\n",
       "0  2019      1        0.0        0.0        1.0        0.0        0.0   \n",
       "1  2019      1        0.0        0.0        1.0        0.0        0.0   \n",
       "2  2019      1        0.0        0.0        1.0        0.0        0.0   \n",
       "3  2019      1        0.0        0.0        1.0        0.0        0.0   \n",
       "4  2019      1        0.0        0.0        1.0        0.0        0.0   \n",
       "\n",
       "   weekday_6  weekday_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        0.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_encoded_df = pd.concat([time_encoded_df, weekday_encoded_df], axis=1)\n",
    "time_encoded_df = time_encoded_df.drop([\"weekday\"], axis=1)\n",
    "time_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Merchant\n",
    "# merch_encoder = OneHotEncoder()\n",
    "# merch_encoder.fit(fraud_dataset_copy[\"merchant\"].to_numpy().reshape(-1, 1))\n",
    "# encoded_merch_values = merch_encoder.fit_transform(fraud_dataset_copy[['merchant']]).toarray()\n",
    "\n",
    "# merch_encoded_df = pd.DataFrame(encoded_merch_values, columns=merch_encoder.get_feature_names())\n",
    "# merch_encoded_df.head()\n",
    "# print(len(merch_encoded_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Category\n",
    "# category_encoder = OneHotEncoder()\n",
    "# category_encoder.fit(fraud_dataset_copy[\"merchant\"].to_numpy().reshape(-1, 1))\n",
    "# encoded_category_values = category_encoder.fit_transform(fraud_dataset_copy[['merchant']]).toarray()\n",
    "\n",
    "# category_encoded_df = pd.DataFrame(encoded_category_values, columns=category_encoder.get_feature_names())\n",
    "# category_encoded_df.head()\n",
    "# print(len(category_encoded_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Encode sex\n",
    "sex_encoder = OneHotEncoder()\n",
    "sex_encoder.fit(fraud_dataset[\"sex\"].to_numpy().reshape(-1, 1))\n",
    "encoded_sex_values = sex_encoder.fit_transform(fraud_dataset[['sex']]).toarray()\n",
    "\n",
    "sex_encoded_df = pd.DataFrame(encoded_sex_values, columns=sex_encoder.get_feature_names_out())\n",
    "sex_encoded_df.head()\n",
    "print(len(sex_encoded_df.columns))\n",
    "\n",
    "del encoded_sex_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode state\n",
    "state_encoder = OneHotEncoder()\n",
    "state_encoder.fit(fraud_dataset[\"state\"].to_numpy().reshape(-1, 1))\n",
    "encoded_state_values = state_encoder.fit_transform(fraud_dataset[['state']]).toarray()\n",
    "\n",
    "state_encoded_df = pd.DataFrame(encoded_state_values, columns=state_encoder.get_feature_names_out())\n",
    "state_encoded_df.head()\n",
    "\n",
    "del encoded_state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode city\n",
    "# city_encoder = OneHotEncoder()\n",
    "# city_encoder.fit(fraud_dataset_copy[\"city\"].to_numpy().reshape(-1, 1))\n",
    "# encoded_city_values = city_encoder.fit_transform(fraud_dataset_copy[['city']]).toarray()\n",
    "\n",
    "# city_encoded_df = pd.DataFrame(encoded_city_values, columns=city_encoder.get_feature_names())\n",
    "# city_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Employment\n",
    "employment_encoder = OneHotEncoder()\n",
    "employment_encoder.fit(fraud_dataset[\"job\"].to_numpy().reshape(-1, 1))\n",
    "encoded_employment_values = employment_encoder.fit_transform(fraud_dataset[['job']]).toarray()\n",
    "\n",
    "job_encoded_df = pd.DataFrame(encoded_employment_values, columns=employment_encoder.get_feature_names_out())\n",
    "job_encoded_df.head()\n",
    "\n",
    "del encoded_employment_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(employment_encoder.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_employment_df = pd.DataFrame(encoded_employment_values, columns=employment_encoder.get_feature_names())\n",
    "# encoded_employment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last sex                        street            city state    zip  \\\n",
       "0    Banks   F                561 Perry Cove  Moravian Falls    NC  28654   \n",
       "1     Gill   F  43039 Riley Greens Suite 393          Orient    WA  99160   \n",
       "2  Sanchez   M      594 White Dale Suite 530      Malad City    ID  83252   \n",
       "3    White   M   9443 Cynthia Court Apt. 038         Boulder    MT  59632   \n",
       "4   Garcia   M              408 Bradley Rest        Doe Hill    VA  24433   \n",
       "\n",
       "       lat      long  city_pop                                job         dob  \\\n",
       "0  36.0788  -81.1781      3495          Psychologist, counselling  1988-03-09   \n",
       "1  48.8878 -118.2105       149  Special educational needs teacher  1978-06-21   \n",
       "2  42.1808 -112.2620      4154        Nature conservation officer  1962-01-19   \n",
       "3  46.2306 -112.1138      1939                    Patent attorney  1967-01-12   \n",
       "4  38.4207  -79.4629        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns = [\"Unnamed: 0\", \"cc_num\", \"trans_date_trans_time\"]\n",
    "fraud_dataset.drop(drop_columns, axis=1, inplace=True)\n",
    "fraud_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"first\", \"last\", \"zip\", \"lat\", \"long\", \"merch_lat\", \"merch_long\", \"trans_num\", \"unix_time\", \"street\"]\n",
    "fraud_dataset.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop modified columns from dataset\n",
    "fraud_dataset = fraud_dataset.drop([\"category\", \"sex\", \"merchant\", \"state\", \"city\", \"job\", \"dob\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([time_encoded_df, fraud_dataset], axis=1)\n",
    "total_df.head()\n",
    "\n",
    "del time_encoded_df\n",
    "del fraud_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([total_df, sex_encoded_df], axis=1)\n",
    "total_df.head()\n",
    "\n",
    "del sex_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([total_df, state_encoded_df], axis=1)\n",
    "total_df.head()\n",
    "del state_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([total_df, job_encoded_df], axis=1)\n",
    "del job_encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - required due to different orders of magnitude across the features\n",
    "# make sure to save the scaler for future use in inference\n",
    "\n",
    "feature_info = {}\n",
    "feature_year_info = {}\n",
    "feature_month_info = {}\n",
    "feature_amt_info = {}\n",
    "feature_pop_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_year_info[\"mean\"] = total_df[\"year\"].mean()\n",
    "feature_year_info[\"std\"] = total_df[\"year\"].std()\n",
    "feature_info[\"year\"] = feature_year_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_month_info[\"mean\"] = total_df[\"month\"].mean()\n",
    "feature_month_info[\"std\"] = total_df[\"month\"].std()\n",
    "feature_info[\"month\"] = feature_month_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_amt_info[\"mean\"] = total_df[\"amt\"].mean()\n",
    "feature_amt_info[\"std\"] = total_df[\"amt\"].std()\n",
    "feature_info[\"amt\"] = feature_amt_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pop_info[\"mean\"] = total_df[\"city_pop\"].mean()\n",
    "feature_pop_info[\"std\"] = total_df[\"city_pop\"].std()\n",
    "feature_info[\"city_pop\"] = feature_pop_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale feature train inputs\n",
    "total_df.loc[:, \"year_scaled\"] = (total_df[\"year\"]-feature_year_info[\"mean\"])/feature_year_info[\"std\"] \n",
    "total_df.loc[:, \"month_scaled\"] = (total_df[\"month\"]-feature_month_info[\"mean\"])/feature_month_info[\"std\"]\n",
    "total_df.loc[:, \"amt_scaled\"] = (total_df[\"amt\"]-feature_amt_info[\"mean\"])/feature_amt_info[\"std\"]\n",
    "total_df.loc[:, \"city_pop_scaled\"] = (total_df[\"city_pop\"]-feature_pop_info[\"mean\"])/feature_pop_info[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.drop([\"year\", \"month\", \"amt\", \"city_pop\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_1</th>\n",
       "      <th>x0_2</th>\n",
       "      <th>x0_3</th>\n",
       "      <th>x0_4</th>\n",
       "      <th>x0_5</th>\n",
       "      <th>x0_6</th>\n",
       "      <th>x0_7</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>x0_AK</th>\n",
       "      <th>x0_AL</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Waste management officer</th>\n",
       "      <th>x0_Water engineer</th>\n",
       "      <th>x0_Water quality scientist</th>\n",
       "      <th>x0_Web designer</th>\n",
       "      <th>x0_Wellsite geologist</th>\n",
       "      <th>x0_Writer</th>\n",
       "      <th>year_scaled</th>\n",
       "      <th>month_scaled</th>\n",
       "      <th>amt_scaled</th>\n",
       "      <th>city_pop_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001455</td>\n",
       "      <td>-1.796248</td>\n",
       "      <td>-0.408741</td>\n",
       "      <td>-0.282428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001455</td>\n",
       "      <td>-1.796248</td>\n",
       "      <td>0.233378</td>\n",
       "      <td>-0.293527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001455</td>\n",
       "      <td>-1.796248</td>\n",
       "      <td>0.942183</td>\n",
       "      <td>-0.280243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001455</td>\n",
       "      <td>-1.796248</td>\n",
       "      <td>-0.157381</td>\n",
       "      <td>-0.287590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.001455</td>\n",
       "      <td>-1.796248</td>\n",
       "      <td>-0.176470</td>\n",
       "      <td>-0.293693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_1  x0_2  x0_3  x0_4  x0_5  x0_6  x0_7  is_fraud  x0_AK  x0_AL  ...  \\\n",
       "0   0.0   0.0   1.0   0.0   0.0   0.0   0.0         0    0.0    0.0  ...   \n",
       "1   0.0   0.0   1.0   0.0   0.0   0.0   0.0         0    0.0    0.0  ...   \n",
       "2   0.0   0.0   1.0   0.0   0.0   0.0   0.0         0    0.0    0.0  ...   \n",
       "3   0.0   0.0   1.0   0.0   0.0   0.0   0.0         0    0.0    0.0  ...   \n",
       "4   0.0   0.0   1.0   0.0   0.0   0.0   0.0         0    0.0    0.0  ...   \n",
       "\n",
       "   x0_Waste management officer  x0_Water engineer  x0_Water quality scientist  \\\n",
       "0                          0.0                0.0                         0.0   \n",
       "1                          0.0                0.0                         0.0   \n",
       "2                          0.0                0.0                         0.0   \n",
       "3                          0.0                0.0                         0.0   \n",
       "4                          0.0                0.0                         0.0   \n",
       "\n",
       "   x0_Web designer  x0_Wellsite geologist  x0_Writer  year_scaled  \\\n",
       "0              0.0                    0.0        0.0    -1.001455   \n",
       "1              0.0                    0.0        0.0    -1.001455   \n",
       "2              0.0                    0.0        0.0    -1.001455   \n",
       "3              0.0                    0.0        0.0    -1.001455   \n",
       "4              0.0                    0.0        0.0    -1.001455   \n",
       "\n",
       "   month_scaled  amt_scaled  city_pop_scaled  \n",
       "0     -1.796248   -0.408741        -0.282428  \n",
       "1     -1.796248    0.233378        -0.293527  \n",
       "2     -1.796248    0.942183        -0.280243  \n",
       "3     -1.796248   -0.157381        -0.287590  \n",
       "4     -1.796248   -0.176470        -0.293693  \n",
       "\n",
       "[5 rows x 560 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "K means clustering is used for grouping together clusters. The strategy was to try different clusters and check if a particular cluster contained a large percentage of fraud instances. The non-fraud instances in that cluster are the ones that should be investigated for fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = KMeans(n_clusters = num_clusters, random_state = 0, n_init='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = cluster_model.fit_predict(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"cluster_labels\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = total_df[total_df[\"is_fraud\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 contains 176 fraud points out of 82861 total instance in the cluster - 0.2 %\n",
      "Cluster 2 contains 571 fraud points out of 245145 total instance in the cluster - 0.2 %\n",
      "Cluster 3 contains 561 fraud points out of 234316 total instance in the cluster - 0.2 %\n",
      "Cluster 4 contains 991 fraud points out of 221788 total instance in the cluster - 0.4 %\n",
      "Cluster 5 contains 481 fraud points out of 270917 total instance in the cluster - 0.2 %\n",
      "Cluster 6 contains 767 fraud points out of 251605 total instance in the cluster - 0.3 %\n",
      "Cluster 7 contains 589 fraud points out of 179463 total instance in the cluster - 0.3 %\n",
      "Cluster 8 contains 368 fraud points out of 145026 total instance in the cluster - 0.3 %\n",
      "Cluster 9 contains 4499 fraud points out of 14445 total instance in the cluster - 31.1 %\n",
      "Cluster 10 contains 0 fraud points out of 0 total instance in the cluster - 0 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, num_clusters+1):\n",
    "    cluster_filter_fraud = fraud_df[fraud_df[\"cluster_labels\"] == i]\n",
    "    num_fraud = len(cluster_filter_fraud)\n",
    "\n",
    "    cluster_filtered_all = total_df[total_df[\"cluster_labels\"] == i]\n",
    "    num_total = len(cluster_filtered_all)\n",
    "    try:\n",
    "        percent_fraud = num_fraud/num_total\n",
    "    except:\n",
    "        percent_fraud = 0\n",
    "    print(\"Cluster {} contains {} fraud points out of {} total instance in the cluster - {} %\".format(i, num_fraud, num_total, round(percent_fraud, 3)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some experimentation, it was found that 10 clusters revealed the seperation of instances of fraud in one cluster.\n",
    "\n",
    "31 percent of cluster 9 are fraud instances, therefore I'd send off the remainder of points in cluster 9 to the data engineer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_send = total_df[total_df[\"cluster_labels\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_send = points_to_send[points_to_send[\"is_fraud\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9946\n"
     ]
    }
   ],
   "source": [
    "print(len(points_to_send))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still quite a few points, so maybe additional clustering could be done on only cluster 9. PCA could also be done on the original dataset in order to shrink the number of dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
