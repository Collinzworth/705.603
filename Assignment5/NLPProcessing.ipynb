{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "050206c0",
   "metadata": {},
   "source": [
    "## Sentiment Web service.  \n",
    "* Use the Restaurant_Reviews.tsv for data\n",
    "* Convert the various text strings into useful vectors for training and inference.  Inference receives a text phrase from a web GET."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c4098",
   "metadata": {},
   "source": [
    "## Assignment \n",
    "1. Populate the natural_language_processing.py following the hints in the comments\n",
    "1. Integrate with natural_language_processing_Service.py\n",
    "1. Test locally\n",
    "1. Build requirements.txt and Dockerfile\n",
    "1. Build a docker image\n",
    "1. Test Locally\n",
    "1. Push to docker hub\n",
    "1. Populate readme for both github and docker hub (with example docker commands)\n",
    "1. Populate this notebook with working output and a summary that contains an impression of the model and how to improve it.\n",
    "* Check the rubric in canvas to make sure you understand the requirements and the assocated weights for your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3cc0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natural_language_processing import Sentiment\n",
    "se = Sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f06a4",
   "metadata": {},
   "source": [
    "### Test Model first - Get stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3a21d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.735'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.model_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b7582",
   "metadata": {},
   "source": [
    "### Get Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0734b57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.model_infer(\"this place is awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb5300",
   "metadata": {},
   "source": [
    "### Start up the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7037761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting server...\n",
      " * Serving Flask app 'natural_language_processing_Service'\n",
      " * Debug mode: off\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8786\n",
      " * Running on http://172.17.0.2:8786\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "172.17.0.1 - - [01/Oct/2023 22:25:02] \"GET /stats HTTP/1.1\" 200 -\n",
      "172.17.0.1 - - [01/Oct/2023 22:25:05] \"GET /infer?sentence=\"This%20place%20is%20really%20bad%20absolutly%20the%20worse\" HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python natural_language_processing_Service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bdbe1",
   "metadata": {},
   "source": [
    "Try out the links \n",
    "* [stats](http://localhost:8786/stats)\n",
    "* [determination](http://localhost:8786/infer?sentence=%22This%20place%20is%20really%20bad%20absolutly%20the%20worse%22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552c40d",
   "metadata": {},
   "source": [
    "### You must kill the kernel to try again for the port stays locked to the current kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88815bab",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* Assignment and Model Results\n",
    "* Techniques to improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f636a87",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278af24",
   "metadata": {},
   "source": [
    "PUT YOUR ANSWERS HERE which could include additional cells with working code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc568d64",
   "metadata": {},
   "source": [
    "The model is able to vectorize the training data and fit a Naive Bayes classifier that produces decent results in predicting if a review is bad or not. The score is ~70% accurate, so more times than not it is correct. Language that is easily distinguishable as positive or negative, such as \"I love this place\", can be identified by the model quite easily. Sceneriods where the review is good and bad or neither will cause problems. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239d080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.model_infer(\"I'm not so sure about this place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0bcaf",
   "metadata": {},
   "source": [
    "Being unsure about something is certainly not positive but not necesarily negative either. However, when it comes to reviews, I would consider unsure to be more negative than positive. Instances like this will cause the natural language processing algorithm a lot of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4a43c",
   "metadata": {},
   "source": [
    "### Improvement Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15a206",
   "metadata": {},
   "source": [
    "Improvement could be made by adding more outlier examples likes the one shown above. There could also be a classification that is \"neutral\" instead of binary good/bad. As far as improving the results, different stemming could be experimented with to improve the data quality inputted to the model. While exploring the data, Porter stemmer can cause some odd results by truncating the ends of strings in strange ways. On top of refining the data quality, more data could also be used to improve the accuracy. \n",
    "\n",
    "Another possible avenue of improvement is to more carefully examine the stopwords that are removed from the dataset. It might take quite some time to get the right set of stopwords for a given application. The variety in language makes this process difficult, but including all of the most important words with minimal non-important words is likely to produce the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
